# -*- coding: utf-8 -*-
"""Predict_randomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_f1LNrTDsOwSb-Fb0nqH3D1WOOIG7gtq
"""

import os
import pandas as pd
import numpy as np


# read data.
traindata = pd.read_csv('train_final.csv')
testdata = pd.read_csv('test_final.csv')

# fill missing features.
traindata = traindata.replace(' ?', np.nan)
for index, row in traindata.iteritems():
    traindata[index].fillna(traindata[index].mode()[0], inplace=True)
testdata = testdata.replace(' ?', np.nan)
for index, row in testdata.iteritems():
    testdata[index].fillna(testdata[index].mode()[0], inplace=True)
traindata.head()

# get labels.
YTrain = traindata['income>50K'].replace([' <=50K' , ' >50K'], [0, 1])

# get features.
XTrain = traindata.drop(['income>50K'], axis=1)
XTest = testdata.drop(['ID'], axis=1)
# normalize numeric features.
from sklearn.preprocessing import StandardScaler
numcol = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']
scaler = StandardScaler()
XTrain[numcol] = scaler.fit_transform(XTrain[numcol])
XTest[numcol] = scaler.transform(XTest[numcol])
# get one-hot vectors.
X = pd.concat([XTrain,XTest])
X = pd.get_dummies(X)
XTrain = X[:len(XTrain)]
XTest = X[len(XTrain):]
print(XTrain)
print("size of training data is", XTrain.shape)
print("size of testing data is", XTest.shape)

# Random Forest.
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=1000, max_depth=None, criterion='gini', max_features=None, min_samples_split=320, min_samples_leaf=4, n_jobs=-1, verbose=1, random_state=0)
model.fit(XTrain, YTrain)
YPred = model.predict(XTest)

testdata['income>50K'] = YPred
testdata['income>50K'] = testdata['income>50K']
print(YPred)
result = testdata[['ID', 'income>50K']]
result.rename(columns = {'income>50K':'Prediction'}, inplace = True)
#result.to_csv('result.csv', index=0)
type(result)

